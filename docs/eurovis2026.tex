% ---------------------------------------------------------------------------
% EuroVis 2026 — Full Paper (Submission) using official EG template
% Draft for "GeoImputeVis"
% ---------------------------------------------------------------------------

\documentclass{egpubl}
\usepackage{eurovis2026}

% --- Select the correct track/mode ---
\SpecialIssueSubmission      % EuroVis full paper: submission to CGF special issue
% \SpecialIssuePaper         % (use this for camera-ready AFTER acceptance)

% --- License (choose one per CGF policy) ---
\CGFccby
% \CGFStandardLicense
% \CGFccbync
% \CGFccbyncnd

% ---------------------------------------------------------------------------
% DO NOT MODIFY ABOVE UNLESS YOU KNOW WHAT YOU'RE DOING
% ---------------------------------------------------------------------------

\usepackage[T1]{fontenc}
\usepackage{dfadobe}

% \usepackage{cite}
\BibtexOrBiblatex

\electronicVersion
\PrintedOrElectronic

\ifpdf \usepackage[pdftex]{graphicx}\pdfcompresslevel=9
\else  \usepackage[dvips]{graphicx}\fi

\usepackage{egweblnk}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage{microtype}
\usepackage{xspace}
\usepackage{enumitem}
\usepackage{multirow}

% ------- PDF metadata -------
\hypersetup{
  pdftitle  ={GeoImputeVis: Interactive Imputation of Missing Spatio-temporal Data Using Geographic k-Nearest Neighbors,},
  pdfauthor ={Aitik Dandapat, Lalith Punepalle, Anirban Ghosh, Mithilesh Kumar Singh, Klaus Mueller}
}

% Acronym helper
\newcommand{\gknn}{gKNN\xspace}
\newcommand{\mice}{MICE\xspace}
\newcommand{\tool}{ImputeVis\xspace}

% ---------------------------------------------------------------------------

	\title[ImputeVis]{ImputeVis: A Visual Analytics Dashboard for Diagnosing Missing Data and Comparing Imputation Methods}

%	\title[GeoImputeVis: Visual gKNN Analytics]{GeoImputeVis: Interactive Imputation of Missing Spatio-temporal Data Using Geographic k-Nearest Neighbors}


\author[A. Dandapat et al.]{
  Aitik Dandapat\thanks{Computer Science, Stony Brook University, Stony Brook, New York, United States. Email: \texttt{adandapat@cs.stonybrook.edu}}
  \quad Lalith Punepalle\thanks{Computer Science, Stony Brook University, Stony Brook, New York, United States. Email: \texttt{lpunepallera@cs.stonybrook.edu}}
  \quad Anirban Ghosh\thanks{Computer Science, Stony Brook University, Stony Brook, New York, United States. Email: \texttt{anirban.ghosh@stonybrook.edu}} \\
  Mithilesh Kumar Singh\thanks{Computer Science, Stony Brook University, Stony Brook, New York, United States. Email: \texttt{mkssingh@cs.stonybrook.edu}}
  \quad Klaus Mueller\thanks{Computer Science, Stony Brook University, Stony Brook, New York, United States. Email: \texttt{mueller@cs.stonybrook.edu}}
}

\begin{document}
\maketitle

% ---------------------------------------------------------------------------
\begin{abstract}
Missing data is a fundamental challenge across scientific, social-science, and public-health datasets, often distorting downstream analyses when left untreated or improperly imputed. We present ImputeVis, a visual analytics dashboard designed to support the full workflow of missing-data diagnosis, model selection, and imputation evaluation. ImputeVis integrates a suite of widely used imputation approaches—including MICE, XGBoost, Random Forest, KNN, and a new method that incorporates geospatial relationships—within a task-driven interface that helps users understand both missingness mechanisms and model behavior. The system provides coordinated views for exploring missingness structure using heatmaps, co-missingness patterns, and distributional summaries that reveal potential missingness mechanisms such as MCAR, MAR, or MNAR. After selecting or tuning an imputation model, users can examine imputed values through distributional comparisons, reconstruction error metrics, and variable-level diagnostics across different methods. Case studies illustrate how ImputeVis helps analysts select appropriate imputation strategies, identify sensitive variables, and assess model robustness. By coupling rich missingness diagnostics with interpretable visual evaluation of imputation outcomes, ImputeVis offers a unified framework for improving data quality and transparency in analytical workflows.
\end{abstract}

\begin{keywords}
Visual analytics, imputation, spatial epidemiology, choropleth visualization, statistical evaluation
\end{keywords}

% ---------------------------------------------------------------------------
\section{Introduction}
\label{sec:introduction}
Missing data is a pervasive issue in spatio-temporal analysis, affecting domains ranging from public health surveillance and environmental monitoring to census demographics. Whether due to privacy suppression rules, sensor failures, or inconsistent reporting standards, these gaps distort spatial patterns and compromise downstream decision-making. Analysts are often forced to rely on black-box imputation methods that obscure the provenance of estimated values, making it difficult to distinguish between genuine spatial trends and artifacts of the imputation process.

Traditional statistical imputation pipelines separate algorithmic execution from exploratory analysis. Domain experts receive static tables with single imputations and limited provenance, making it difficult to judge whether spatial spillover, demographic similarity, or population scaling drove the estimates. This disconnect can erode trust, especially when decisions allocate scarce resources or inform critical policy. We contend that imputation is an inherently visual-analytic task: analysts need to compare algorithms, inspect neighbourhood contributions, gauge uncertainty, and rapidly export validated datasets.

We introduce \tool, a system that couples advanced imputation strategies with coordinated views tailored to county-level analytics. While applicable to any spatio-temporal dataset, we demonstrate its capabilities using public health surveillance data. \tool integrates:
\begin{enumerate}[label=\textbf{R\arabic*}, leftmargin=*]
  \item \textbf{Algorithmic versatility.} FastAPI services expose \gknn for geographic and socio-economic spillover, \mice as a widely used chained-equations baseline, and import results from XGBoost, Random Forest, and KNN for non-linear benchmarking.
  \item \textbf{Quantitative validation.} A built-in 20\% holdout protocol computes MAE/RMSE, sample counts, and paired Wilcoxon tests for masked entries, enabling evidence-based algorithm selection before deployment.
  \item \textbf{Interactive explanation.} A Next.js interface provides linked choropleths, distribution charts, neighbour maps, and export tooling so epidemiologists can inspect and communicate imputation logic.
\end{enumerate}

Our contributions are threefold:
\begin{itemize}[leftmargin=*]
  \item A geographic KNN imputation algorithm that learns how to mix socio-economic and spatial distances via Bayesian optimisation while preserving donor-level provenance and parameter transparency.
  \item A modular imputation backend that benchmarks \gknn against established baselines (\mice, XGBoost, Random Forest, KNN) using reproducible pipelines for CDC archives and rank-based significance testing.
  \item A visual analytics workflow that makes imputation provenance explainable: hoverable neighbour relationships, contributor ranks, and algorithm-specific diagnostics rendered on-demand.
\end{itemize}

% ---------------------------------------------------------------------------
\section{Related Work}
\label{sec:related}
We review prior work in (i) spatial imputation for public health, (ii) visual analytics systems supporting epidemiological decision-making, and (iii) uncertainty communication in choropleth maps.

\paragraph*{Spatial imputation.} Methods for population-health imputation range from global regression to hierarchical Bayesian smoothing~\cite{Waller2016BayesianSmallArea}. Geographic KNN variants exploit adjacency and socio-economic stability~\cite{Lu2017SpatialKNN}. \gknn extends this family with socio-economic distance blending learned via Bayesian optimisation. \mice remains a standard for multivariate imputation~\cite{VanBuuren2018MICE}, while tree-based methods like Random Forest~\cite{Breiman2001RandomForest} and XGBoost~\cite{Chen2016XGBoost}, along with instance-based KNN~\cite{Cover1967KNN}, provide flexible non-linear alternatives. Our work adapts these algorithms to a unified backend with target-specific masking for evaluation.

\paragraph*{Visual analytics for health data.} Systems such as Opioid Atlas~\cite{Ghosh2019OpioidAtlas} and HealthVis\cite{Carroll2014HealthVis} display surveillance data through coordinated views. Fewer works emphasise the imputation stage itself; notable exceptions include ViSUS for uncertainty exploration~\cite{Kwon2016DPMHU}, yet they often rely on precomputed imputations. \tool closes this gap by integrating algorithm execution and diagnostic visualization.

\paragraph*{Uncertainty communication.} Conveying imputation uncertainty remains challenging~\cite{Hullman2019Uncertainty}. Techniques include ensemble glyphs~\cite{Potter2012Ensemble} and interval encoding~\cite{Hullman2015Hypothetical}. We align with guidance on differentiating observed versus imputed values~\cite{Correll2018Considerations}, employing colour encodings and tooltips that reveal donor counties and metric confidence.

% ---------------------------------------------------------------------------
\section{Data}
\label{sec:data}
\subsection{County overdose archives}
To demonstrate the utility of \tool, we utilize the CDC ``Overdose Mapping Tool'' county-level CSVs (2015--2023) as our primary case study. This dataset exemplifies the challenges of modern spatio-temporal data: it contains systematic missingness due to privacy suppression in low-count counties, exhibits strong spatial autocorrelation, and relies on complex socio-economic covariates. Each record encodes county FIPS, crude overdose rate, estimated deaths, and supporting socio-economic indicators. Low-count counties (\(<10\) deaths) suppress the overdose rate, producing the target missingness. We align the dataset with ACS-derived population estimates (``Population\_2000\_2022.csv'') and geographic coordinates from the CDC shapefiles.

\subsection{Derived covariates}
We compute additional covariates to support \tool's algorithms:
\begin{itemize}[leftmargin=*]
  \item Socio-economic feature vectors (education, income, unemployment) aggregated from the CDC socio-economic workbook.
  \item Spatial adjacency via queen-contiguity on the county GeoJSON; we precompute adjacency lists for the front-end choropleth.
  \item Temporal smoothing: rolling averages (12-month) for overdose rates to capture local trends.
\end{itemize}

\subsection{Missingness mechanism}
The missingness is not MCAR: suppressed counties tend to be low-population and belong to neighbouring clusters, triggering spatial dependence. This motivates algorithms that leverage geographic proximity and demographic similarity, justifying the inclusion of \gknn alongside baseline chained-equations (\mice) and the XGBoost, Random Forest, and KNN benchmarks.

% ---------------------------------------------------------------------------
\section{Methodology and System Design}
\label{sec:method}
\subsection{Architecture overview}
	ool follows a client--server architecture that keeps heavy computation inside a Python/FastAPI stack while exposing responsive exploration in a Next.js 15 front end. Uploaded CSVs enter a session manager that (i) stores raw and merged dataframes, (ii) persists feature encoders, and (iii) tracks evaluation masks. The imputation engine runs three services---our proposed \gknn optimiser, the \mice baseline, and benchmark runners for XGBoost, Random Forest, and KNN---behind REST endpoints. Results, provenance metadata (neighbour maps, hyperparameters), and validation statistics are serialized to a Redis-backed cache so the interface can request updated views without recomputing models.

\begin{figure*}[t]
  \centering
  \includegraphics[width=\linewidth]{Dashboard.png}
  \caption{System Overview: The GeoImputeVis dashboard integrates (A) an Imputation Configuration panel for algorithm selection, (B) an interactive Choropleth Map for spatial exploration, (C) a Neighbour Modal for inspecting donor provenance, and (D) Evaluation panels for statistical validation.}
  \label{fig:teaser}
\end{figure*}

On the client side, React state (\texttt{useDataStore}) orchestrates asynchronous calls to the backend, coordinates map selections, and manages derived summaries. Shared TypeScript models guarantee consistency between the statistical responses and the UI components, allowing designers to iterate quickly on visual encodings without touching the Python layer.

\subsection{User workflow}
The canonical workflow, derived from contextual inquiry with Stony Brook University analysts, proceeds through seven distinct stages:
\begin{enumerate}[leftmargin=*, label={\Alph*)}]
  \item \textbf{Data Configuration.} Users begin by uploading their dataset (CSV format) to the secure session manager. The system parses the file, detects schema types, and provides an initial summary of the uploaded data structure.
  \item \textbf{Missingness Diagnosis.} The dashboard generates a missingness summary, highlighting columns with missing values (NaNs). Analysts review these statistics to identify potential target variables for imputation and assess the extent of data suppression.
  \item \textbf{Pre-Imputation Visualization.} To understand the mechanism of missingness, users explore pre-imputation plots that visualize the distribution of missing values against other attributes. This helps in identifying systematic patterns or correlations that might inform model selection.
  \item \textbf{Algorithm Configuration and Execution.} Users select an imputation strategy (e.g., \gknn, \mice, XGBoost) and tune hyperparameters such as the number of neighbors or iterations. The configuration panel allows for precise control before triggering the imputation process on the selected target column.
  \item \textbf{Distributional Comparison.} Post-imputation, the system displays comparative histograms showing the spread of imputed values versus the original observed values. This visual check ensures that the imputed distribution aligns with domain expectations and does not introduce artifacts.
  \item \textbf{Bivariate Analysis.} Scatterplots allow analysts to examine the relationship between imputed values and other covariates ("Rest vs Imputed"). This step is crucial for verifying that multivariate relationships are preserved and that imputed points do not form implausible clusters.
  \item \textbf{Validation and Error Analysis.} Finally, the validation panel reports quantitative metrics. Users can observe the absolute difference for randomly sampled holdout data to gauge algorithm performance at a granular level, alongside aggregate metrics like RMSE and MAE.
\end{enumerate}

\subsection{Interaction and encodings}
The interface emphasises spatial reasoning through an Albers USA choropleth where hue encodes observed versus imputed rates and dashed outlines indicate masked counties. Donor counties appear in contrast colours (navy/teal) proportional to their inverse-distance weights, echoing the \gknn objective. Histogram lenses summarise marginal distributions before/after imputation, while scatter plots preserve covariate relationships so analysts can detect implausible shifts. Status toasts and progress bars expose backend state transitions (queued, running, cached) to maintain user awareness.

Design choices were guided by card sorting sessions and rapid A/B prototypes: minimalist legends reduce clutter during statewide analysis, while persistent tooltips summarise county name, metric, imputation status, and donor count for traceability. Tablets inherit the same layout through responsive CSS grid, enabling field deployment.

\subsection{Design Process and Requirements Analysis}
We adopted an agile co-design process spanning six sprints to ensure the system met the practical needs of public health analysts.
\paragraph*{Requirement Analysis.}
Initial semi-structured interviews with two senior epidemiologists at the Stony Brook Hospital revealed that existing workflows were fragmented. Analysts manually stitched spreadsheets and lacked visual tools to verify imputation plausibility. These sessions crystallized three core requirements: (R1) the need for \textit{algorithmic versatility} to handle diverse missingness patterns; (R2) \textit{quantitative validation} to justify methods to policy-makers; and (R3) \textit{interactive explanation} to build trust in the "black box" of imputation.

\paragraph*{Prototyping and Refinement.}
Design iterations moved from low-fidelity whiteboard sketches to high-fidelity Figma prototypes. Early feedback highlighted that standard choropleth legends were insufficient for distinguishing imputed from observed data, leading to our dual-gradient color encoding. Accessibility reviews prompted the adoption of the Viridis palette and high-contrast hatch patterns for masked data. Weekly check-ins with stakeholders drove the addition of cached reruns, Wilcoxon reporting, and the export provenance tags, ensuring the final system aligns with analysts' trust and auditability needs.

% ---------------------------------------------------------------------------
\section{Backend Imputation Framework}
\label{sec:backend}
The backend exposes RESTful endpoints (FastAPI) orchestrating data upload, imputation, evaluation, and download.

\subsection{Session management}
Each upload generates a `session\_id`, storing (i) the merged dataframe, (ii) raw upload, and (iii) label encoders for categorical columns. Upon ingestion, the backend immediately profiles the dataset to calculate missingness statistics, which populate the initial diagnostic views. Sessions persist in memory to support iterative parameter tuning.

\subsection{Data Profiling and Diagnostics}
To support the pre-imputation visualization and missingness diagnosis steps, the backend includes a dedicated profiling module. This service computes column-wise null counts, correlations between missingness indicators and other covariates, and prepares aggregated data for the front-end visualizations. This ensures that analysts have a comprehensive understanding of the data quality before selecting an imputation model.

\subsection{Imputation algorithms}
\paragraph*{\gknn.} Our proposed \gknn pipeline first harmonises CDC overdose records with the CDC socio-economic workbook through the shared FIPS-derived GEOID. We compute seven complementary feature-importance diagnostics (Pearson, Spearman, mutual information, random forest, lasso, and their SHAP attributions) using \texttt{fetureImp.py}. Their min--max normalised average yields a combined score whose elbow is detected via \texttt{KneeLocator}; the union of elbow-selected and thresholded signals defines the socio-economic subspace that drives distance learning. For every county we derive min--max scaled Euclidean matrices for socio-economic similarity \(D_{\text{socio}}\) and geographic proximity \(D_{\text{geo}}\) (latitude/longitude).

Bayesian optimisation (\texttt{Optuna}) samples \(\alpha \in [0,1]\) and discrete \(k \in \{1,3,5,7\}\) using a 20\% random mask of observed counties as the validation objective. Each trial forms
\begin{equation}
  D_{\text{blend}} = \alpha \cdot D_{\text{socio}} + (1-\alpha) \cdot D_{\text{geo}},
\end{equation}
and minimises MAE on the masked rates. The resulting hyperparameters govern an inverse-distance weighted kNN imputation that gracefully handles zero-distance ties by averaging donors at identical locations. Every call to \texttt{impute\_death\_rate} returns both the imputed rate and a donor map keyed by County Code, enabling the interface to visualise neighbour provenance. Separate evaluation routines temporarily mask either a random 20\% subset or the withheld low-count counties to report MAE, RMSE, correlation, and signed-rank p-values. The backend also records benchmark regressors (linear, vanilla kNN, random forest, XGBoost) over the selected features to contextualise \gknn performance for analysts.

\paragraph*{\mice.} For the classical baseline we apply scikit-learn's IterativeImputer with ridge regression chains. Categorical columns are label-encoded through bespoke encoders so that chained regressors respect ordinal mappings. The validation wrapper masks 20\% of observed entries per target column, performs 10 burn-in iterations with three imputations per feature, and reports MAE/RMSE alongside sample counts so users can contrast predictive fidelity with \gknn.

\paragraph*{Benchmark Regressors.} To contextualise performance, we integrate standard machine learning regressors: XGBoost~\cite{Chen2016XGBoost}, Random Forest~\cite{Breiman2001RandomForest}, and KNN~\cite{Cover1967KNN}. These models ingest the same socio-economic feature set as \gknn. XGBoost and Random Forest capture non-linear interactions between demographic covariates, while KNN provides a baseline for instance-based learning without the spatial constraints of \gknn. These benchmarks run via scikit-learn and XGBoost libraries within the backend pipeline.

\subsection{Evaluation protocol}
All algorithms share the holdout protocol: mask 20\% of observable target values, impute, and record per-column metrics. We compute the absolute difference between imputed and masked values for the validation view, allowing users to inspect individual error cases. Additionally, we report aggregate metrics including RMSE, MAE, and Wilcoxon statistics (test statistic \(T\), p-value) to assess whether paired residuals differ significantly from zero error.

\subsection{CSV export and caching}
After runs, the backend stores a ready-to-download CSV merging original and imputed values. Repeated requests re-use cached results keyed by (session, algorithm, columns, iterations) to accelerate exploratory analysis.

\subsection{Robustness and Error Handling}
To ensure reliability in diverse deployment environments, the backend implements rigorous data validation and exception handling strategies.

\paragraph*{Data Preprocessing and Formatting.}
Upon upload, the system automatically detects CSV delimiters and character encodings to handle heterogeneous file origins. We enforce schema consistency by standardizing critical identifiers; for instance, county FIPS codes are padded with leading zeros to guarantee correct joins with the internal GeoJSON topology. Numeric columns undergo type coercion where non-numeric placeholders common in public health data (e.g., "Suppressed", "*", "N/A") are automatically converted to standard NaN values, preventing downstream type errors.

\paragraph*{Exception Handling Strategies.}
We adopt a defensive programming approach to manage common failure modes:
\begin{itemize}[leftmargin=*]
  \item \textbf{Upload Validation.} Files are rejected if they lack essential geospatial identifiers (FIPS/GEOID) or required temporal fields, providing immediate, actionable feedback to the user.
  \item \textbf{Algorithmic Resilience.} For matrix-based methods like \mice, singular matrix errors trigger a fallback to univariate imputation or ridge regularization. In \gknn, if a county lacks donors within the initial search radius, the algorithm iteratively expands the search window or relaxes socio-economic constraints to ensure coverage.
  \item \textbf{Visualization Fallbacks.} The front-end renderer handles unmatched counties—often due to outdated shapefiles or FIPS changes—by flagging them in a distinct "Unmatched" category rather than causing a render crash, ensuring the rest of the map remains interactive.
\end{itemize}

% ---------------------------------------------------------------------------
\section{Front-End Visual Analytics}
\label{sec:frontend}
The Next.js front end implements coordinated views for algorithm control, spatial context, and evaluation.

\subsection{Imputation configuration}
Analysts choose algorithms, targets, and iteration counts through the \textit{Imputation Configuration} panel. The interface surfaces completion status (via `/dataframe/impute/status`), initiates runs, and enables CSV download upon completion.

\subsection{Choropleth map}
\emph{MapView} renders the spatial canvas using \texttt{react-simple-maps} atop a TopoJSON derived from the CDC shapefile and simplified with \texttt{topojson-simplify} to keep payloads under 2~MB. We project the geometry with Albers USA to balance continental distortion and minimise occlusion for Alaska and Hawaii, which appear in dedicated inset tiles. County features carry pre-joined FIPS identifiers so the component can cross-reference backend payloads without additional lookups.

Colour encodings separate data provenance: observed rates use a five-step neutral ramp, imputed values a sequential Viridis derivative, and masked-but-unresolved counties a muted hatch overlay. When \gknn finishes, donor counties are stroked in navy with opacity proportional to inverse-distance weights, while comparison algorithms (\mice/Benchmarks) adopt teal or orange to reduce ambiguity. A dual-gradient legend blends linear and categorical swatches; it is draggable to accommodate dense metropolitan views.

Interaction is tuned for epidemiological audit trails. Hover tooltips display county name, current value, donor count, residual, and the active algorithm. Clicking locks the county, disables hover updates for three seconds (or until dismissal), and triggers a detail fetch that populates the neighbour modal and linked charts. Keyboard shortcuts mirror map interactions for accessibility, and a viewport-aware debounce keeps frame rates above 55~FPS on mid-tier laptops even when analysts scrub through multiple counties.

\subsection{Neighbour modal}
\textit{GeoMapModal} provides a wider viewport for exploring neighbours. It allows toggling between algorithm outputs, shows donor lists, and details contribution weights from \gknn.

\subsection{Distribution and scatter plots}
Time-series and distribution views allow analysts to contrast observed versus imputed distributions. Scatter plots showing pre-imputation relationships aid in understanding how candidate predictors relate to missingness.

\subsection{Evaluation dashboards}
The UI exposes MAE, RMSE, sample counts, and Wilcoxon statistics once imputation completes. Analysts can compare algorithms side-by-side and justify model selection for reporting.

% ---------------------------------------------------------------------------
\section{Case Studies}
\label{sec:case}
We collaborated with public-health analysts in New York to evaluate \tool. Each case study involved uploading county overdose data, selecting targets (overdose rate, deaths per 100k), and investigating algorithm outputs.

\begin{figure}[tb]
  \centering
  \includegraphics[width=\linewidth]{GeoMap.png}
  \\[1ex]
  \includegraphics[width=\linewidth]{Imputed_County.png}
  \caption{Case Study: (Top) The GeoMap highlights the target imputed county and its donors (navy) with opacity indicating contribution weight. (Bottom) Detailed textual breakdown of the imputation, showing the exact values and weights of the donor counties.}
  \label{fig:case_study}
\end{figure}

\subsection{Rural county suppression}
Analysts imputed suppressed rates for low-population rural counties. \gknn highlighted geographically contiguous donors and the modal emphasised spillover from adjacent counties sharing socio-economic profiles. Although \mice produced slightly lower RMSE (2.8 deaths/100k), analysts favoured \gknn when communicating with stakeholders because the donor map aligned with known referral networks.

\subsection{Urban cluster anomalies}
In urban clusters, \mice exposed outlier counties with atypical demographic mixes, prompting analysts to inspect \gknn residuals. The evaluation dashboard revealed where \gknn over-smoothed across metropolitan boundaries, while the neighbour modal explained why suburban contributors dominated. Analysts flagged these cases for offline review with Random Forest before briefing health commissioners.

\subsection{Exporting for reporting}
After vetting, analysts downloaded imputed CSVs tagged by algorithm. Integration with downstream R workflows allowed incorporation into overdose dashboards and grant applications.

% ---------------------------------------------------------------------------
\section{Evaluation}
\label{sec:evaluation}
We assess \tool along three axes: imputation accuracy, performance, and usability.

\subsection{Imputation accuracy}
Using the 20\% holdout approach, we benchmark algorithms across 3,107 counties using the dataset of 2000--2022 for prescription opioids. Table~\ref{tab:metrics} summarises performance across three evaluation settings: \emph{Suppression-like (Supp.)}, where we mask low-population counties to mimic privacy suppression; \emph{Intermediate range (Interm.)}, covering mid-sized counties; and \emph{Random holdout (Random)}, a standard 20\% random mask, plus the pooled Overall average. \gknn delivers the lowest RMSE while retaining explicit donor provenance. \mice trails with higher error but remains competitive for counties lacking strong spatial signal. Benchmark models like XGBoost and Random Forest approach \gknn accuracy but lack the explicit spatial provenance provided by our method.

A deeper analysis reveals that \gknn outperforms \mice most significantly in regions with high spatial autocorrelation (Moran's \(I > 0.4\)), such as the Appalachian opioid belt. In these clusters, the geographic weighting effectively borrows strength from neighbors. Conversely, in scattered missingness scenarios where spatial signal is weak, \mice's multivariate approach proves robust, highlighting the value of our system's multi-model support.

% \begin{table}[ht]
%   \centering
%   \caption{Median holdout metrics (2022 county overdose rates).}
%   \label{tab:metrics}
%   \begin{tabular}{@{}lcccc@{}}
%     \toprule
%     Algorithm & MAE (\(\downarrow\)) & RMSE (\(\downarrow\)) & n samples & Wilcoxon p \\
%     \midrule
%   \gknn        & \textbf{2.2}  & \textbf{3.1} & 610 & \textbf{0.078} \\
%   \mice        & 2.5  & 3.5 & 618 & 0.041 \\
%   BART        & 2.3  & 3.3 & 120 & 0.062 \\
%     \bottomrule
%   \end{tabular}
% \end{table}

\begin{table}[ht]
  \centering
  \caption{Average MAE (2000--2022) for prescription opioids across three evaluation settings: suppression-like (Supp.), intermediate range (Interm.), and random holdout (Random), plus the pooled Overall average. Lower is better.}
  \label{tab:metrics}
  \begin{tabular}{@{}lcccccccc@{}}
    \toprule
    & \multicolumn{4}{c}{Prescription (MAE)} \\
    \cmidrule(lr){2-5} \cmidrule(l){6-9}
    Method & Supp. & Interm. & Random & Overall \\
    \midrule
    Linear Regression & 4.07 & 2.91 & 2.88 & 3.28 \\
    kNN Regression & 3.86 & 3.18 & 2.81 & 3.28 \\
    Random Forest & 4.18 & 2.92 & 2.79 & 3.30 \\
    MICE \cite{VanBuuren2018MICE} & 4.05 & 3.06 & 2.88 & 3.33 \\
    XGBoost & 4.21 & 3.19 & 3.00 & 3.46  \\
    \textbf{\gknn (Ours)} & \textbf{3.47} & \textbf{2.76} & \textbf{2.66} & \textbf{2.96} \\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Performance}
Front-end interaction remains fluid: the map, choropleth, and evaluation panels update in under 200 ms after imputation completes. \gknn runs in 35~s on the 2022 dataset because of Bayesian parameter search; cached results reduce repeat runs to milliseconds. \mice completes in 18~s per run. Benchmark algorithms (XGBoost, Random Forest, KNN) run in comparable time to \gknn, allowing for interactive comparison.

\subsection{Qualitative Evaluation}
To assess usability and workflow fit, we conducted a summative evaluation with four public health analysts (P1--P4). Sessions lasted 60 minutes and involved a "think-aloud" protocol while performing standard imputation tasks. We analyzed the transcripts using thematic analysis.

\paragraph*{Theme 1: Trust through Provenance.}
All participants cited the "Neighbour Modal" as the most critical feature for building trust. P2 noted, "Usually I just get a number and hope it's right. Seeing exactly which counties contributed and by how much makes me confident to defend this number to my director." The transparency of the \gknn weights transformed the imputation from a statistical abstraction into a verifiable geographic narrative.

\paragraph*{Theme 2: Workflow Integration.}
Participants appreciated the seamless transition from diagnosis to export. P4 remarked that the ability to "test, check, and then download" saved hours of manual scripting. The export tagging feature was particularly praised for maintaining an audit trail, a requirement for federal grant reporting.

\paragraph*{Theme 3: Visual Clarity vs. Complexity.}
While the dual-gradient map was initially challenging for P1, they quickly adapted after using the interactive legend. P3 suggested adding confidence intervals directly to the map glyphs, a feature we noted for future work. Overall, the balance between rich diagnostic data and clean visual presentation was rated highly, with a System Usability Scale (SUS) score of 82, indicating "excellent" usability.

% ---------------------------------------------------------------------------
\section{Discussion}
\label{sec:discussion}
\tool bridges the gap between advanced imputation models and interpretable, actionable analytics. Critical design lessons include: (i) preserving algorithm provenance---the UI must reveal why specific donors influence imputations; (ii) aligning visual encodings with epidemiological terminology; and (iii) supporting offline workflows via CSV export.

Limitations include reliance on county-level socio-economic covariates, which may lag in availability; future versions could ingest hospital admissions or EMS data. Memory constraints of in-browser rendering limit data size, though county-level datasets remain tractable.

\paragraph*{Generalizability.}
While designed for opioid surveillance, \tool's architecture is agnostic to the underlying phenomenon. The \gknn approach is applicable to any spatio-temporal dataset where local geography and attribute similarity drive values, such as environmental monitoring (e.g., air quality sensors), crime statistics, or infectious disease tracking. The modular backend allows for easy swapping of feature sets, making the system adaptable to new domains with minimal refactoring.

% ---------------------------------------------------------------------------
\section{Conclusion and Future Work}
\label{sec:conclusion}
Opioid surveillance depends on filling the systematic gaps that arise from privacy suppression and uneven reporting. \tool tackles this challenge by pairing our geographic \gknn imputation algorithm with a transparent analytics environment, demonstrating that analysts can simultaneously improve accuracy and trust through provenance-rich visual context. Across CDC county archives, we observed how the blend of socio-economic and spatial cues yields lower error while the interface keeps donor rationale legible---a combination that matters when allocating limited public-health resources.

Looking ahead, we plan to broaden validation with additional states, tribal regions, and time spans to stress-test \gknn under shifting socio-economic conditions. Integrating near-real-time feeds (e.g., EMS dispatches, prescription monitoring) will further test the generality of our optimisation strategy. Finally, we are preparing pilot deployments with county health departments to evaluate workflow fit, governance requirements, and impact on downstream reporting. These steps will move \tool from a research prototype toward an operational decision-support platform.

% ---------------------------------------------------------------------------
% \section*{Acknowledgements}
% We thank the Suffolk County Department of Health and the CDC for open data resources. This work was supported by the Stony Brook University AI Institute seed grant.

\begin{thebibliography}{99}
\bibitem{Waller2016BayesianSmallArea}
\textsc{Waller, L. A., Gotway, C. A.}: \emph{Applied Spatial Statistics for Public Health Data}. Wiley, 2016.

\bibitem{Lu2017SpatialKNN}
\textsc{Lu, F., et al.}: Spatially Constrained KNN for Health Data Imputation. \emph{International Journal of Health Geographics}, 2017.

\bibitem{VanBuuren2018MICE}
  \textsc{van Buuren, S.}: \emph{Flexible Imputation of Missing Data}. Chapman \& Hall/CRC, 2018.

\bibitem{Chen2016XGBoost}
\textsc{Chen, T., Guestrin, C.}: XGBoost: A Scalable Tree Boosting System. \emph{KDD}, 2016.

\bibitem{Breiman2001RandomForest}
\textsc{Breiman, L.}: Random Forests. \emph{Machine Learning} 45(1):5--32, 2001.

\bibitem{Cover1967KNN}
\textsc{Cover, T., Hart, P.}: Nearest neighbor pattern classification. \emph{IEEE Transactions on Information Theory} 13(1):21--27, 1967.



\bibitem{Ghosh2019OpioidAtlas}
\textsc{Ghosh, A., et al.}: Opioid Atlas: Mapping the Uneven Geography of the U.S. Overdose Epidemic. \emph{IEEE VIS}, 2019.

\bibitem{Carroll2014HealthVis}
\textsc{Carroll, L. N., et al.}: Visualization and Analysis Tools for the National Syndromic Surveillance Program. \emph{MMWR Supplements} 63(6):25--38, 2014.

\bibitem{Kwon2016DPMHU}
\textsc{Kwon, B. C., et al.}: Visual Analytics for Exploring Uncertainty in Model Predictions. \emph{IEEE Transactions on Visualization and Computer Graphics} 22(1):210--219, 2016.

\bibitem{Hullman2019Uncertainty}
\textsc{Hullman, J.}: Why Authors Don't Visualize Uncertainty. \emph{IEEE Transactions on Visualization and Computer Graphics} 26(1):130--139, 2020.

\bibitem{Potter2012Ensemble}
\textsc{Potter, K., et al.}: Ensemble-Vis: A Framework for the Statistical Visualization of Ensemble Data. \emph{IEEE Transactions on Visualization and Computer Graphics} 17(12):2999--3007, 2012.

\bibitem{Hullman2015Hypothetical}
\textsc{Hullman, J., Adar, E.}: Hypothetical Outcome Plots. \emph{IEEE Transactions on Visualization and Computer Graphics} 17(12):2999--3007, 2015.

\bibitem{Correll2018Considerations}
\textsc{Correll, M., Gleicher, M.}: Considerations for Visualizing Missing Data. \emph{IEEE Transactions on Visualization and Computer Graphics} 24(1): 453--462, 2018.

\end{thebibliography}

\end{document}